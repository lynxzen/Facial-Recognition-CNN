{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83685288",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26bbed",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a2dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('dataset/') \n",
    "\n",
    "SEED_VALUE = 7\n",
    "SHUFFLE_MODE = True\n",
    "VAL_SPLIT = 0.3\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d76236",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "directory = data_dir,\n",
    "labels = 'inferred',\n",
    "label_mode = 'categorical',\n",
    "image_size = IMG_SIZE,\n",
    "validation_split = VAL_SPLIT,\n",
    "subset = \"training\",\n",
    "seed = SEED_VALUE,\n",
    "shuffle = SHUFFLE_MODE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "directory = data_dir,\n",
    "labels = 'inferred',\n",
    "label_mode = 'categorical',\n",
    "image_size = IMG_SIZE,\n",
    "validation_split = VAL_SPLIT,\n",
    "subset = \"validation\",\n",
    "seed = SEED_VALUE,\n",
    "shuffle = SHUFFLE_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92b7df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8f9fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677090bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomBrightness(0.2),\n",
    "  tf.keras.layers.RandomContrast(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeaaddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fe7c6",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc224a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca93c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6f9c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0408f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ab96a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180d740",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.layers.Lambda(lambda x: preprocess_input(x), output_shape=(224, 224, 3))(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cfe89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25679800",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b939c2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72bfb03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_epochs = 5\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e561fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8fd7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=2,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b1515",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save(\"fr_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a0a6c",
   "metadata": {},
   "source": [
    "# Model verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd78fa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"fr_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca6519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abe37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(label_batch, axis=1)\n",
    "\n",
    "print('Predictions:\\n', predicted_classes)\n",
    "print('Labels:\\n', true_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    plt.title(class_names[predicted_classes[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d7331",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "single_image = image_batch[0:1]\n",
    "predictions = model.predict(single_image)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "predicted_class_name = class_names[predicted_class_index[0]]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(single_image[0].astype(\"uint8\")) \n",
    "plt.title(f'Predicted: {predicted_class_name}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(file_path):\n",
    "    img = tf.keras.utils.load_img(\n",
    "    file_path, target_size=(224, 224)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    \n",
    "    if predictions.shape[0] == 1:\n",
    "        predictions = predictions[0]  \n",
    "\n",
    "    zipped_results = list(zip(class_names, predictions))\n",
    "\n",
    "    for class_name, prediction in zipped_results:\n",
    "        print(f'Class: {class_name}, Prediction: {prediction}')\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {}.\"\n",
    "        .format(class_names[np.argmax(score)])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "josh_path = '2a0a8ccc-7c1a-11ee-9b35-244bfe0536bf.jpg'\n",
    "josh_img = prediction(josh_path)\n",
    "\n",
    "sara_path = '6c5e4a9d-e809-11ee-9b1b-6c6a77a009ff.jpg'\n",
    "sara_img = prediction(sara_path)\n",
    "\n",
    "jad_path = '8bcc6c48-e7d9-11ee-b856-7a8da97ec93a.jpg'\n",
    "jad_img = prediction(jad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_path = 'IMG_1200.jpeg'\n",
    "rob_img = prediction(rob_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a3d85",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75952329",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_mode = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def predict_image(image):\n",
    "    img_array = np.expand_dims(image, axis=0)\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    \n",
    "    if predictions.shape[0] == 1:\n",
    "        predictions = predictions[0]  \n",
    "\n",
    "    zipped_results = list(zip(class_names, predictions))\n",
    "\n",
    "    for class_name, prediction in zipped_results:\n",
    "        print(f'Class: {class_name}, Prediction: {prediction}')\n",
    "    \n",
    "    print(\n",
    "        \"This image most likely belongs to {}.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "    return img_array, np.argmax(score)\n",
    "\n",
    "def update_model(img_array, correct_label):\n",
    "    model.fit(img_array, tf.keras.utils.to_categorical([correct_label], num_classes=len(class_names)), verbose=0)\n",
    "\n",
    "print(\"Press 'c' to capture the image and predict, 'u' to toggle update mode, or 'q' to quit.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame. Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Webcam - Press \"c\" to capture and predict, \"u\" to toggle update, \"q\" to quit', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):\n",
    "        if faces is not None:\n",
    "            for (x, y, w, h) in faces:\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "                face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "                face_resized = cv2.resize(face_rgb, (224, 224))\n",
    "                face_preprocessed = tf.keras.applications.vgg16.preprocess_input(face_resized)\n",
    "                img_array, predicted_label = predict_image(face_preprocessed)\n",
    "                print(\"Press a number key to select a label\")\n",
    "                break \n",
    "\n",
    "    elif key == ord('u'):\n",
    "        update_mode = not update_mode\n",
    "        print(f\"Update mode set to {'on' if update_mode else 'off'}.\")\n",
    "        print(f\"Classes: {class_names}\")\n",
    "\n",
    "    elif ord('0') <= key <= ord('9'):\n",
    "        if update_mode:\n",
    "            correct_label = key - ord('0')\n",
    "            if correct_label < len(class_names):\n",
    "                update_model(img_array, correct_label)\n",
    "                print(f\"Classes: {class_names}\")\n",
    "                print(f\"Model updated with label: {class_names[correct_label]}\")\n",
    "            else:\n",
    "                print(\"Invalid class label.\")\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b22a",
   "metadata": {},
   "source": [
    "# Get faces from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a136c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "dataset_dir = 'dataset/Sara/'\n",
    "processed_dir = 'dataset_new/Sara/'\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "for filepath in glob.glob(os.path.join(dataset_dir, '*.jpg')):\n",
    "    filename = os.path.basename(filepath)\n",
    "    img = cv2.imread(filepath)\n",
    "    if img is not None:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            resized_face = cv2.resize(face, (224, 224))\n",
    "\n",
    "            save_path = os.path.join(processed_dir, f\"{filename[:-4]}_face_{i}.jpg\")\n",
    "            cv2.imwrite(save_path, resized_face)\n",
    "            print(f\"Processed and saved face: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f643270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
